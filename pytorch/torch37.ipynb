{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os, re, random, time\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 2\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "MAX_LENGTH = 20\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self):\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(\" \"):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "\n",
    "# 3\n",
    "def normalizeString(df, lang):\n",
    "    sentence = df[lang].str.lower()\n",
    "    sentence = sentence.str.replace(\"[^A-Za-z\\s]+\", \" \")\n",
    "    sentence = sentence.str.normalize(\"NFD\")\n",
    "    sentence = sentence.str.encode(\"ascii\", errors=\"ignore\").str.decode(\"utf-8\")\n",
    "    return sentence\n",
    "\n",
    "\n",
    "def read_sentence(df, lang1, lang2):\n",
    "    sentence1 = normalizeString(df, lang1)\n",
    "    sentence2 = normalizeString(df, lang2)\n",
    "    return sentence1, sentence2\n",
    "\n",
    "\n",
    "def read_file(loc, lang1, lang2):\n",
    "    df = pd.read_csv(loc, delimiter=\"\\t\", header=None, names=[lang1, lang2])\n",
    "    return df\n",
    "\n",
    "\n",
    "def process_data(lang1, lang2):\n",
    "    df = read_file(\n",
    "        \"C://chungnam_chatbot/pytorch/data2/%s-%s.txt\" % (lang1, lang2), lang1, lang2\n",
    "    )\n",
    "    sentence1, sentence2 = read_sentence(df, lang1, lang2)\n",
    "\n",
    "    input_lang = Lang()\n",
    "    output_lang = Lang()\n",
    "    pairs = []\n",
    "    for i in range(len(df)):\n",
    "        if (\n",
    "            len(sentence1[i].split(\" \")) < MAX_LENGTH\n",
    "            and len(sentence2[i].split(\" \")) < MAX_LENGTH\n",
    "        ):\n",
    "            full = [sentence1[i], sentence2[i]]\n",
    "            input_lang.addSentence(sentence1[i])\n",
    "            output_lang.addSentence(sentence2[i])\n",
    "            pairs.append(full)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "# 4\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(\" \")]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorFromPair(input_lang, output_lang, pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    output_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, output_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 encoder\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, embbed_dim, num_layers):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.embbed_dim = embbed_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(input_dim, self.embbed_dim)\n",
    "        self.gru = nn.GRU(self.embbed_dim, self.hidden_dim, num_layers=self.num_layers)\n",
    "\n",
    "    def forward(self, src):\n",
    "        embedded = self.embedding(src).view(1, 1, -1)\n",
    "        outputs, hidden = self.gru(embedded)\n",
    "        return outputs, hidden\n",
    "\n",
    "\n",
    "# 12 attension\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1\n",
    "        )\n",
    "        attn_applied = torch.bmm(\n",
    "            attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0)\n",
    "        )\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 seq2seq\n",
    "class AttnSeq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device, MAX_LENGTH=MAX_LENGTH):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, input_lang, output_lang, teacher_forcing_ratio=0.5):\n",
    "        input_length = input_lang.size(0)\n",
    "        batch_size = output_lang.shape[1]\n",
    "        target_length = output_lang.shape[0]\n",
    "        vocab_size = self.decoder.output_size\n",
    "        outputs = torch.zeros(target_length, batch_size, vocab_size).to(self.device)\n",
    "\n",
    "        for i in range(input_length):\n",
    "            encoder_output, encoder_hidden = self.encoder(input_lang[i])\n",
    "        decoder_hidden = encoder_hidden.to(device)\n",
    "        decoder_input = torch.tensor([SOS_token], device=device)\n",
    "\n",
    "        for t in range(target_length):\n",
    "            decoder_output, decoder_hidden, encoder_output = self.decoder(\n",
    "                decoder_input, decoder_hidden, encoder_output\n",
    "            )\n",
    "            outputs[t] = decoder_output\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            input = output_lang[t] if teacher_force else topi\n",
    "            if teacher_force == False and input.item() == EOS_token:\n",
    "                break\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 model, loss\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def makeModel(model, input_tensor, target_tensor, model_optimizer, criterion):\n",
    "    model_optimizer.zero_grad()\n",
    "    input_length = input_tensor.size(0)\n",
    "    loss = 0\n",
    "    epoch_loss = 0\n",
    "    output = model(input_tensor, target_tensor)\n",
    "    num_iter = output.size(0)\n",
    "\n",
    "    for ot in range(num_iter):\n",
    "        loss += criterion(output[ot], target_tensor[ot])\n",
    "    loss.backward()\n",
    "    model_optimizer.step()\n",
    "    epoch_loss = loss.item() / num_iter\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13 train\n",
    "\n",
    "\n",
    "def trainIters(\n",
    "    model, encoder, decoder, n_iters, print_every=1000, plot_every=100, lr=0.01\n",
    "):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0\n",
    "    plot_loss_total = 0\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=lr)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=lr)\n",
    "    training_pairs = [\n",
    "        tensorFromPair(input_lang, output_lang, random.choice(pairs))\n",
    "        for i in range(n_iters)\n",
    "    ]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "        loss = makeModel(\n",
    "            model, input_tensor, target_tensor, decoder_optimizer, criterion\n",
    "        )\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % 5000 == 0:\n",
    "            print_loss_avg = print_loss_total / 5000\n",
    "            print_loss_total = 0\n",
    "            print(f\"Iter: {iter}, Loss avg: {print_loss_avg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 evaluate\n",
    "def evaluate(model, input_lang, output_lang, sentences, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentences[0])\n",
    "        output_tensor = tensorFromSentence(output_lang, sentences[1])\n",
    "        decoded_words = []\n",
    "        output = model(input_tensor, output_tensor)\n",
    "\n",
    "        for ot in range(output.size(0)):\n",
    "            topv, topi = output[ot].topk(1)\n",
    "            if topi[0].item() == EOS_token:\n",
    "                decoded_words.append(\"<EOS>\")\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi[0].item()])\n",
    "    return decoded_words\n",
    "\n",
    "\n",
    "def evaluateRandomly(model, input_lang, output_lang, pairs, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print(\"input\", pair[0])\n",
    "        print(\"output\", pair[1])\n",
    "        output_words = evaluate(model, input_lang, output_lang, pair)\n",
    "        output_sentence = \" \".join(output_words)\n",
    "        print(\"predicted : \", output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "randomize sentence ['i think about you all day long.', 'je pense a toi toute la journee.']\n",
      "Encoder(\n",
      "  (embedding): Embedding(23191, 256)\n",
      "  (gru): GRU(256, 512)\n",
      ")\n",
      "AttnDecoderRNN(\n",
      "  (embedding): Embedding(39387, 512)\n",
      "  (attn): Linear(in_features=1024, out_features=20, bias=True)\n",
      "  (attn_combine): Linear(in_features=1024, out_features=512, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (gru): GRU(512, 512)\n",
      "  (out): Linear(in_features=512, out_features=39387, bias=True)\n",
      ")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "batch2 must be a 3D tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[39mprint\u001b[39m(encoder1)\n\u001b[0;32m     21\u001b[0m \u001b[39mprint\u001b[39m(attn_decoder1)\n\u001b[1;32m---> 23\u001b[0m attn_model \u001b[39m=\u001b[39m trainIters(model, encoder1, attn_decoder1, \u001b[39m75000\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[26], line 24\u001b[0m, in \u001b[0;36mtrainIters\u001b[1;34m(model, encoder, decoder, n_iters, print_every, plot_every, lr)\u001b[0m\n\u001b[0;32m     22\u001b[0m input_tensor \u001b[39m=\u001b[39m training_pair[\u001b[39m0\u001b[39m]\n\u001b[0;32m     23\u001b[0m target_tensor \u001b[39m=\u001b[39m training_pair[\u001b[39m1\u001b[39m]\n\u001b[1;32m---> 24\u001b[0m loss \u001b[39m=\u001b[39m makeModel(\n\u001b[0;32m     25\u001b[0m     model, input_tensor, target_tensor, decoder_optimizer, criterion\n\u001b[0;32m     26\u001b[0m )\n\u001b[0;32m     27\u001b[0m print_loss_total \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\n\u001b[0;32m     28\u001b[0m plot_loss_total \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\n",
      "Cell \u001b[1;32mIn[16], line 10\u001b[0m, in \u001b[0;36mmakeModel\u001b[1;34m(model, input_tensor, target_tensor, model_optimizer, criterion)\u001b[0m\n\u001b[0;32m      8\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m      9\u001b[0m epoch_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m---> 10\u001b[0m output \u001b[39m=\u001b[39m model(input_tensor, target_tensor)\n\u001b[0;32m     11\u001b[0m num_iter \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[39mfor\u001b[39;00m ot \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_iter):\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[15], line 22\u001b[0m, in \u001b[0;36mAttnSeq2Seq.forward\u001b[1;34m(self, input_lang, output_lang, teacher_forcing_ratio)\u001b[0m\n\u001b[0;32m     19\u001b[0m decoder_input \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([SOS_token], device\u001b[39m=\u001b[39mdevice)\n\u001b[0;32m     21\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(target_length):\n\u001b[1;32m---> 22\u001b[0m     decoder_output, decoder_hidden, encoder_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(\n\u001b[0;32m     23\u001b[0m         decoder_input, decoder_hidden, encoder_output\n\u001b[0;32m     24\u001b[0m     )\n\u001b[0;32m     25\u001b[0m     outputs[t] \u001b[39m=\u001b[39m decoder_output\n\u001b[0;32m     26\u001b[0m     teacher_force \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39mrandom() \u001b[39m<\u001b[39m teacher_forcing_ratio\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[14], line 41\u001b[0m, in \u001b[0;36mAttnDecoderRNN.forward\u001b[1;34m(self, input, hidden, encoder_outputs)\u001b[0m\n\u001b[0;32m     36\u001b[0m embedded \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(embedded)\n\u001b[0;32m     38\u001b[0m attn_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39msoftmax(\n\u001b[0;32m     39\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattn(torch\u001b[39m.\u001b[39mcat((embedded[\u001b[39m0\u001b[39m], hidden[\u001b[39m0\u001b[39m]), \u001b[39m1\u001b[39m)), dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m     40\u001b[0m )\n\u001b[1;32m---> 41\u001b[0m attn_applied \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mbmm(\n\u001b[0;32m     42\u001b[0m     attn_weights\u001b[39m.\u001b[39;49munsqueeze(\u001b[39m0\u001b[39;49m), encoder_outputs\u001b[39m.\u001b[39;49munsqueeze(\u001b[39m0\u001b[39;49m)\n\u001b[0;32m     43\u001b[0m )\n\u001b[0;32m     45\u001b[0m output \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((embedded[\u001b[39m0\u001b[39m], attn_applied[\u001b[39m0\u001b[39m]), \u001b[39m1\u001b[39m)\n\u001b[0;32m     46\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattn_combine(output)\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: batch2 must be a 3D tensor"
     ]
    }
   ],
   "source": [
    "# 14\n",
    "lang1 = \"eng\"\n",
    "lang2 = \"fra\"\n",
    "input_lang, output_lang, pairs = process_data(lang1, lang2)\n",
    "\n",
    "randomize = random.choice(pairs)\n",
    "print(\"randomize sentence\", randomize)\n",
    "\n",
    "\n",
    "embed_size = 256\n",
    "hidden_size = 512\n",
    "num_layers = 1\n",
    "input_size = input_lang.n_words\n",
    "output_size = output_lang.n_words\n",
    "\n",
    "encoder1 = Encoder(input_size, hidden_size, embed_size, num_layers)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_size, dropout_p=0.1).to(device)\n",
    "model = AttnSeq2Seq(encoder1, attn_decoder1, device).to(device)\n",
    "\n",
    "print(encoder1)\n",
    "print(attn_decoder1)\n",
    "\n",
    "attn_model = trainIters(model, encoder1, attn_decoder1, 75000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
